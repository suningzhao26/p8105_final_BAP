---
title: "data_import_cleaning"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(patchwork)
library(viridis)
library(haven)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

check variables in daily parameters, and daily aqi tables:

```{r}
daily_ny_2008_co = read_csv("./data/daily_parameter/co/daily_42101_2008.csv") %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York")
```

```{r}
daily_ny_2008_no2 = read_csv("./data/daily_parameter/no2/daily_42602_2008.csv") %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York")
```

```{r}
daily_aqi = read_csv("./data/daily_aqi/daily_aqi_by_county_2008.csv")

daily_aqi_data = daily_aqi %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York")
```

## Data integrating and cleaning for daily aqi

### Daily aqi for each county in New York State from 2003 to 2010.

```{r}
full_aqi = 
  tibble(
    files = list.files("data/daily_aqi/"),
    path = str_c("data/daily_aqi/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York") %>% 
  select(-files, -path) %>% 
  select(state = state_name, county = county_name, date, aqi, category, defining_parameter, defining_site, site_num = number_of_sites_reporting)
```

## daily parameter value

manipulate a relatively small file firstly:

```{r}
sample_ozone = read_csv("./data/daily_parameter/ozone/daily_ozone_2008.csv") %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York") %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```


There is a large file storage complication which would block the push. So we need to make a pre-processing for `ozone`, `pm2.5`, and `so2` folder (those folders contain raw data files that exceed 100 M). This process is in another document.

After the pre-processing, files in `ozone`, `pm2.5`, and `so2` folder contain data for New York State, others contain data across the US.


## Data integrating and cleaning for 6 daily parameter values

### Ozone, 10 years, New York state

```{r}
full_ozone = 
  tibble(
    files = list.files("data/daily_parameter/ozone/"),
    path = str_c("data/daily_parameter/ozone/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```

### CO, 10 years, New York State

```{r}
full_co = 
  tibble(
    files = list.files("data/daily_parameter/co/"),
    path = str_c("data/daily_parameter/co/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York") %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```

### NO2, 10 years, New York State

```{r}
full_no2 = 
  tibble(
    files = list.files("data/daily_parameter/no2/"),
    path = str_c("data/daily_parameter/no2/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York") %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```

### SO2, 10 years, New York State

```{r}
full_so2 = 
  tibble(
    files = list.files("data/daily_parameter/so2/"),
    path = str_c("data/daily_parameter/so2/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```

### PM2.5, 10 years, New York State

```{r}
full_pm2_5 = 
  tibble(
    files = list.files("data/daily_parameter/pm2.5/"),
    path = str_c("data/daily_parameter/pm2.5/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```

### PM10, 10 years, New York State

```{r}
full_pm10 = 
  tibble(
    files = list.files("data/daily_parameter/pm10/"),
    path = str_c("data/daily_parameter/pm10/", files)
  ) %>% 
  mutate(data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  janitor::clean_names() %>% 
  filter(state_name == "New York") %>% 
  select(state = state_name, city = city_name, county = county_name, site = local_site_name, date = date_local, parameter_name, max = x1st_max_value, mean = arithmetic_mean, units_of_measure, observation_count, latitude, longitude)
```


## Extract daily parameter mean value from different sites for each county.

### Ozone (unit of measure: parts per million)

```{r}
ozone = full_ozone %>% 
  group_by(county, date) %>% 
  summarize(
    mean_ozone = mean(mean),
    max_ozone = mean(max)
  )
```

### CO (unit of measure: parts per million)

```{r}
co = full_co %>% 
  group_by(county, date) %>% 
  summarize(
    mean_co = mean(mean),
    max_co = mean(max)
  )
```

### NO2 (unit of measure: parts per million)

```{r}
no2 = full_no2 %>% 
  group_by(county, date) %>% 
  summarize(
    mean_no2 = mean(mean),
    max_no2 = mean(max)
  )
```

### SO2 (unit of measure: parts per million)

```{r}
so2 = full_so2 %>% 
  group_by(county, date) %>% 
  summarize(
    mean_so2 = mean(mean),
    max_so2 = mean(max)
  )
```

### PM2.5 (unit of measure: Micrograms/cubic meter (LC))

```{r}
pm2_5 = full_pm2_5 %>% 
  group_by(county, date) %>% 
  summarize(
    mean_pm2_5 = mean(mean),
    max_pm2_5 = mean(max)
  )
```

### PM10 (unit of measure: Micrograms/cubic meter (25 C))

```{r}
pm10 = full_pm10 %>% 
  group_by(county, date) %>% 
  summarize(
    mean_pm10 = mean(mean),
    max_pm10 = mean(max)
  )
```


## Merge daily aqi and daily parameter tables

```{r}
air_daily = 
  left_join(full_aqi, ozone, by = c("county", "date")) %>% 
  left_join(co, by = c("county", "date")) %>% 
  left_join(no2, by = c("county", "date")) %>%
  left_join(so2, by = c("county", "date")) %>%
  left_join(pm2_5, by = c("county", "date")) %>%
  left_join(pm10, by = c("county", "date")) %>% 
  separate(defining_site, into = c("state_code", "county_code", "site_code"), sep = "-") %>% 
  select(state_code, county_code, everything(), -site_num, -site_code)
```

```{r}
write.csv(air_daily, file = ("./data/air_daily.csv"))
```


Dataset from brfss (raw datasets deleted, too large for push):

Code chunks used:

b2003 = read_xpt("./data/brfss/cdbrfs03.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2, cvdcrhd2, cvdstrk2, asthma2, asthnow, asthmst)


b2004 = read_xpt("./data/brfss/CDBRFS04.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2, cvdcrhd2, cvdstrk2, asthma2, asthnow, asthmst)


b2005 = read_xpt("./data/brfss/CDBRFS05.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr3, cvdcrhd2 = cvdcrhd3, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2006 = read_xpt("./data/brfss/CDBRFS06.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr3, cvdcrhd2 = cvdcrhd3, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2007 = read_xpt("./data/brfss/CDBRFS07.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2008 = read_xpt("./data/brfss/CDBRFS08.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2009 = read_xpt("./data/brfss/CDBRFS09.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2010 = read_xpt("./data/brfss/CDBRFS10.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2, asthnow, asthmst)


b2011 = read_xpt("./data/brfss/LLCP2011.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode1, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2 = asthma3, asthnow, asthmst = asthms1)


b2012 = read_xpt("./data/brfss/LLCP2012.xpt") %>% 
  janitor::clean_names() %>% 
  filter(state == 36) %>% 
  select(state_code = state, county_code = ctycode1, year = iyear, month = imonth, day = iday, cvdinfr2 = cvdinfr4, cvdcrhd2 = cvdcrhd4, cvdstrk2 = cvdstrk3, asthma2 = asthma3, asthnow, asthmst = asthms1)


write.csv(b2003, file = ("./data/brfss/brfss_ny_2003.csv"))
write.csv(b2004, file = ("./data/brfss/brfss_ny_2004.csv"))
write.csv(b2005, file = ("./data/brfss/brfss_ny_2005.csv"))
write.csv(b2006, file = ("./data/brfss/brfss_ny_2006.csv"))
write.csv(b2007, file = ("./data/brfss/brfss_ny_2007.csv"))
write.csv(b2008, file = ("./data/brfss/brfss_ny_2008.csv"))
write.csv(b2009, file = ("./data/brfss/brfss_ny_2009.csv"))
write.csv(b2010, file = ("./data/brfss/brfss_ny_2010.csv"))
write.csv(b2011, file = ("./data/brfss/brfss_ny_2011.csv"))
write.csv(b2012, file = ("./data/brfss/brfss_ny_2012.csv"))



brfss_indi =  
  bind_rows(b2003, b2004, b2005, b2006, b2007, b2008, b2009, b2010, b2011, b2012) %>%  
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day)
  )

write.csv(brfss_indi, file = ("./data/brfss_indi.csv"))



```{r}
brfs_for_merge = read_csv("./data/brfss_indi.csv") %>% 
  mutate(
    date = as.Date(paste(year,month,day,sep="-"),"%Y-%m-%d")
  ) %>% 
  select(date, county_code, year, month, day, starts_with("cvd"), starts_with("asth"))
```

```{r}
air_daily1 = air_daily %>% 
  mutate(county_code = as.numeric(county_code))

brfss_with_air = 
  left_join(brfs_for_merge, air_daily1, by = c("county_code", "date"))
```

```{r}
write.csv(brfss_with_air, file = ("./data/brfss_with_air.csv"))
```

